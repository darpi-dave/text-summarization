{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from transformers import T5ForConditionalGeneration, T5Tokenizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(text):\n",
    "    # Tokenize text into sentences\n",
    "    sentences = nltk.sent_tokenize(text)\n",
    "    # Joining the sentences again to create a clean text\n",
    "    clean_text = ' '.join(sentences)\n",
    "    return clean_text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c66f09e2632641dfabda7427d40f84a5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/2.32k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\DARPI DAVE\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\huggingface_hub\\file_download.py:139: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\DARPI DAVE\\.cache\\huggingface\\hub\\models--t5-small. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b2d704707aa84bc983778ef4c3abb1ee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "spiece.model:   0%|          | 0.00/792k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "de3633c62375467b8f5a2f8dde3d9d6c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.39M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n"
     ]
    }
   ],
   "source": [
    "# Load T5 Model\n",
    "model_name = 't5-small'  \n",
    "model = T5ForConditionalGeneration.from_pretrained(model_name)\n",
    "tokenizer = T5Tokenizer.from_pretrained(model_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_summary(text, max_input_length=1024, max_output_length=300):  # Increase max_output_length\n",
    "    # Preprocessing and encoding the input text\n",
    "    clean_text = preprocess_text(text)\n",
    "    input_ids = tokenizer.encode(f\"summarize: {clean_text}\", return_tensors=\"pt\", max_length=max_input_length, truncation=True)\n",
    "    \n",
    "    # Generating the summary using the model\n",
    "    summary_ids = model.generate(input_ids, max_length=max_output_length, min_length=80, num_beams=8, length_penalty=2.0, early_stopping=True)\n",
    "\n",
    "    # Decoding the generated summary\n",
    "    summary = tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n",
    "    return summary\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary:  the COVID-19 pandemic has brought significant challenges to global health and economies. governments around the world have imposed lockdowns to contain the virus spread. however, these measures have resulted in substantial economic losses. public health policies have shifted, with a greater emphasis on ensuring access to vaccines and healthcare for vulnerable populations. the global community is grappling with the long-term impacts of the virus on mental health and the economy.\n"
     ]
    }
   ],
   "source": [
    "# Example long document text \n",
    "document = \"\"\"\n",
    "The COVID-19 pandemic has brought significant challenges to global health and economies. Governments around the world have imposed lockdowns to contain the virus spread. However, these measures have resulted in substantial economic losses, particularly for small businesses and individuals who rely on daily wages. On the other hand, the pandemic has also led to innovations in the healthcare sector, such as the rapid development of vaccines and treatments. Public health policies have shifted, with a greater emphasis on ensuring access to vaccines and healthcare for vulnerable populations. As the world continues to battle the pandemic, the global community is also grappling with the long-term impacts of the virus on mental health and the economy.\n",
    "\"\"\"\n",
    "\n",
    "summary = generate_summary(document)\n",
    "print(\"Summary: \", summary)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
